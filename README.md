# ğŸ¤ Voice Emotion Detection using Machine Learning

This project implements a machine learning-based system for detecting emotions from voice recordings. By analyzing audio input, the system identifies emotional states such as happy, sad, angry, surprised, and more.

The core of the project lies in the extraction of audio features using Mel Frequency Cepstral Coefficients (MFCCs), which effectively capture the characteristics of human speech. These features are used to train a Random Forest Classifier that learns to associate speech patterns with specific emotions.

A simple and intuitive user interface is built using **Streamlit**, enabling users to upload audio files in various formats (WAV, MP3, etc.) and get instant emotion predictions.

---

## ğŸ” Features

- Emotion classification using speech signals.
- MFCC-based feature extraction.
- Trained Random Forest model for robust prediction.
- User-friendly web app with file upload and emotion display.
- Supports multiple audio formats for wider usability.

---

## ğŸ› ï¸ Technologies Used

- **Python** â€“ Core programming language.
- **Librosa** â€“ Audio processing and MFCC feature extraction.
- **Scikit-learn** â€“ Machine learning (Random Forest, model evaluation).
- **Streamlit** â€“ Interactive web interface.
- **Pydub** â€“ Audio format conversion.
- **Joblib** â€“ Model saving and loading.

---

## ğŸ“ˆ Project Workflow

1. Audio data is collected from a labeled dataset.
2. MFCC features are extracted from each audio file.
3. A Random Forest classifier is trained using these features.
4. The model is saved for future predictions.
5. A web interface is created to allow users to upload audio and view detected emotions in real-time.


